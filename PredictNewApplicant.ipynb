{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# load the model\n",
    "model = joblib.load('LogisticRegression.joblib') #modify this line to load the model you want to use\n",
    "\n",
    "#load new applicant data\n",
    "new_applicant = pd.read_csv('NewApplicant.csv') #modify this line to load the new applicant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Default[0] | Default[1]\n",
      "------------------------------\n",
      "[[0.97215858 0.02784142]\n",
      " [0.93025153 0.06974847]\n",
      " [0.61638182 0.38361818]\n",
      " [0.47088917 0.52911083]\n",
      " [0.7760443  0.2239557 ]\n",
      " [0.42456998 0.57543002]\n",
      " [0.7781638  0.2218362 ]\n",
      " [0.95025445 0.04974555]\n",
      " [0.54008388 0.45991612]\n",
      " [0.89025176 0.10974824]\n",
      " [0.93686058 0.06313942]\n",
      " [0.95638283 0.04361717]\n",
      " [0.69854793 0.30145207]\n",
      " [0.78951611 0.21048389]\n",
      " [0.91004674 0.08995326]\n",
      " [0.20692712 0.79307288]\n",
      " [0.26306275 0.73693725]\n",
      " [0.95929584 0.04070416]\n",
      " [0.7922884  0.2077116 ]\n",
      " [0.96883617 0.03116383]]\n",
      "[0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#######Preprocess NewApplicant data #######\n",
    "\n",
    "if 'LoanID' in new_applicant.columns:\n",
    "    new_applicant = new_applicant.drop(['LoanID'], axis=1)\n",
    "else:\n",
    "    print('LoanID column is not present or has removed, check the columns')\n",
    "\n",
    "new_applicant['Education'] = new_applicant['Education'].map({'High School':1,'Bachelor\\'s':2, 'Master\\'s':3, 'PhD':4}).astype(int)\n",
    "new_applicant['EmploymentType'] = new_applicant['EmploymentType'].map({'Unemployed':1,'Part-time':2, 'Full-time':3, 'Self-employed':4}).astype(int)\n",
    "new_applicant['MaritalStatus']= new_applicant['MaritalStatus'].map({'Single':1,'Married':2, 'Divorced':3}).astype(int)\n",
    "new_applicant['HasMortgage']= new_applicant['HasMortgage'].map({'No':0,'Yes':1}).astype(int)\n",
    "new_applicant['HasDependents']= new_applicant['HasDependents'].map({'No':0,'Yes':1}).astype(int)\n",
    "new_applicant['LoanPurpose']= new_applicant['LoanPurpose'].map({'Education':1,'Home':2, 'Business':3, 'Auto':4, 'Other':5}).astype(int)\n",
    "new_applicant['HasCoSigner']= new_applicant['HasCoSigner'].map({'No':0,'Yes':1}).astype(int)\n",
    "new_applicant['LoanTerm']= (new_applicant['LoanTerm']/12).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# List of columns to be processed for Z-score normalization\n",
    "new_applicant_independent_variables = ['Age','Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', \\\n",
    "                       'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio']\n",
    "\n",
    "# apply Z-score normalization and rounding to 4 decimal places\n",
    "for column in new_applicant_independent_variables:\n",
    "    new_applicant[column] = scaler.fit_transform(new_applicant[[column]])\n",
    "    new_applicant[column] = new_applicant[column].apply(lambda x: round(x, 4))\n",
    "\n",
    "\n",
    "# drop the MaritalStatus column due to the absence of the column in the train data that has been dropped due to VIF > 3\n",
    "new_applicant = new_applicant.drop(['MaritalStatus'], axis=1)\n",
    "\n",
    "\n",
    "columns_encode = ['Education', 'EmploymentType','LoanPurpose']\n",
    "# One hot encoding for categorical variables #columns_encode is at the train data\n",
    "new_applicant = pd.get_dummies(new_applicant, columns=columns_encode)\n",
    "new_applicant_columns = new_applicant.columns\n",
    "for column in new_applicant_columns:\n",
    "    if new_applicant[column].dtype == bool:\n",
    "        new_applicant[column] = new_applicant[column].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split the new applicant data into features and target variable(Default)\n",
    "X_new_applicant = new_applicant.drop(['Default'], axis=1)\n",
    "Y_new_applicant = new_applicant['Default']\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# predict and check the probability of the new applicant of getting default\n",
    "y_new_applicant_proba = model.predict_proba(X_new_applicant)\n",
    "print(\" Default[0] | Default[1]\")\n",
    "print('-'*30)\n",
    "print(y_new_applicant_proba)\n",
    "\n",
    "# predict using the loaded model with probability score hihger than 0.5(default_value = 0.5) considered as not having default (0)\n",
    "result = np.where(y_new_applicant_proba[:,0] > 0.5, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
